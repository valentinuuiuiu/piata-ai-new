import { NextRequest, NextResponse } from 'next/server';
import fs from 'fs';
import path from 'path';
import { kael } from '../../../lib/kael/orchestrator';
import { getJulesManager } from '../../../lib/jules-manager';

// PAI PUBLIC ENDPOINT - Event Horizon technique
// PAI thinks it's calling the full KAI backend, but gets simplified public access
// No workflow execution, no ChainLink, just basic LLM responses

const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY!;

// PAI Memory System - Simple conversation context
// On Vercel, we must use /tmp for writable storage (ephemeral)
const MEMORY_DIR = path.join('/tmp', 'pai_memory');
const CONVERSATIONS_FILE = path.join(MEMORY_DIR, 'conversations.json');

interface ConversationEntry {
  timestamp: string;
  userMessage: string;
  paiResponse: string;
}

function ensureMemoryDir() {
  if (!fs.existsSync(MEMORY_DIR)) {
    fs.mkdirSync(MEMORY_DIR, { recursive: true });
  }
}

function loadConversations(): ConversationEntry[] {
  try {
    ensureMemoryDir();
    if (fs.existsSync(CONVERSATIONS_FILE)) {
      const data = fs.readFileSync(CONVERSATIONS_FILE, 'utf8');
      return JSON.parse(data);
    }
  } catch (error) {
    console.error('Error loading PAI conversations:', error);
  }
  return [];
}

function saveConversations(conversations: ConversationEntry[]) {
  try {
    ensureMemoryDir();
    // Keep only last 10 conversations for memory efficiency
    const recent = conversations.slice(-10);
    fs.writeFileSync(CONVERSATIONS_FILE, JSON.stringify(recent, null, 2));
  } catch (error) {
    console.error('Error saving PAI conversations:', error);
  }
}

function addToMemory(userMessage: string, paiResponse: string) {
  const conversations = loadConversations();
  conversations.push({
    timestamp: new Date().toISOString(),
    userMessage,
    paiResponse
  });
  saveConversations(conversations);
}

function getConversationContext(): string {
  const conversations = loadConversations();
  const recent = conversations.slice(-3); // Last 3 conversations

  if (recent.length === 0) return '';

  let context = '\n\nCONTEXT DIN CONVERSA»öIILE RECENTE:\n';
  recent.forEach(conv => {
    context += `Utilizator: ${conv.userMessage.substring(0, 40)}...\n`;
    context += `PAI: ${conv.paiResponse.substring(0, 40)}...\n`;
  });

  return context;
}

// PAI Learning System - Analyzes user patterns and adapts responses
interface UserProfile {
  communicationStyle: 'formal' | 'casual' | 'technical' | 'friendly';
  preferredTopics: string[];
  responsePreferences: {
    length: 'short' | 'medium' | 'detailed';
    emojis: boolean;
    technicalLevel: 'basic' | 'intermediate' | 'advanced';
  };
  interactionCount: number;
  lastInteraction: string;
}

const USER_PROFILE_FILE = path.join(MEMORY_DIR, 'user_profile.json');

function loadUserProfile(): UserProfile {
  try {
    ensureMemoryDir();
    if (fs.existsSync(USER_PROFILE_FILE)) {
      const data = fs.readFileSync(USER_PROFILE_FILE, 'utf8');
      return JSON.parse(data);
    }
  } catch (error) {
    console.error('Error loading user profile:', error);
  }

  // Default profile
  return {
    communicationStyle: 'friendly',
    preferredTopics: [],
    responsePreferences: {
      length: 'medium',
      emojis: true,
      technicalLevel: 'basic'
    },
    interactionCount: 0,
    lastInteraction: new Date().toISOString()
  };
}

function saveUserProfile(profile: UserProfile) {
  try {
    ensureMemoryDir();
    fs.writeFileSync(USER_PROFILE_FILE, JSON.stringify(profile, null, 2));
  } catch (error) {
    console.error('Error saving user profile:', error);
  }
}

function analyzeUserMessage(message: string): Partial<UserProfile> {
  const updates: Partial<UserProfile> = {};

  // Analyze communication style
  const formalWords = /\b(domnu(le)?|doamn(a)?|rog|as dori|va rog)\b/gi;
  const technicalWords = /\b(api|database|algorithm|framework|code|programming|server|cloud)\b/gi;
  const casualWords = /\b(hey|salut|ce faci|super|cool|wow)\b/gi;

  const formalCount = (message.match(formalWords) || []).length;
  const technicalCount = (message.match(technicalWords) || []).length;
  const casualCount = (message.match(casualWords) || []).length;

  if (formalCount > technicalCount && formalCount > casualCount) {
    updates.communicationStyle = 'formal';
  } else if (technicalCount > formalCount && technicalCount > casualCount) {
    updates.communicationStyle = 'technical';
  } else if (casualCount > 0) {
    updates.communicationStyle = 'casual';
  }

  // Analyze preferred topics
  const topics = [];
  if (message.toLowerCase().includes('piata') || message.toLowerCase().includes('market')) {
    topics.push('marketplace');
  }
  if (technicalWords.test(message)) {
    topics.push('technology');
  }
  if (message.toLowerCase().includes('ajutor') || message.toLowerCase().includes('help')) {
    topics.push('support');
  }

  if (topics.length > 0) {
    updates.preferredTopics = topics;
  }

  // Analyze response preferences
  const hasEmojis = /[\u{1F600}-\u{1F64F}]|[\u{1F300}-\u{1F5FF}]|[\u{1F680}-\u{1F6FF}]|[\u{1F1E0}-\u{1F1FF}]/u.test(message);
  updates.responsePreferences = {
    emojis: hasEmojis,
    length: message.length > 100 ? 'detailed' : message.length > 50 ? 'medium' : 'short',
    technicalLevel: technicalCount > 2 ? 'advanced' : technicalCount > 0 ? 'intermediate' : 'basic'
  };

  return updates;
}

function adaptSystemPrompt(basePrompt: string, userProfile: UserProfile): string {
  let adaptedPrompt = basePrompt;

  // Adapt communication style
  if (userProfile.communicationStyle === 'formal') {
    adaptedPrompt += '\n\nSTIL DE COMUNICARE: Formal, respectuos, profesionist.';
  } else if (userProfile.communicationStyle === 'technical') {
    adaptedPrompt += '\n\nSTIL DE COMUNICARE: Tehnic, precis, detaliat.';
  } else if (userProfile.communicationStyle === 'casual') {
    adaptedPrompt += '\n\nSTIL DE COMUNICARE: Prietenos, relaxat, conversational.';
  }

  // Adapt response preferences
  if (userProfile.responsePreferences.emojis) {
    adaptedPrompt += '\n\nFOLOSE»òTE EMOJI: Da, pentru a face rƒÉspunsurile mai atractive.';
  } else {
    adaptedPrompt += '\n\nFOLOSE»òTE EMOJI: Nu, pƒÉstreazƒÉ un ton profesional.';
  }

  if (userProfile.responsePreferences.length === 'short') {
    adaptedPrompt += '\n\nLUNGIME RƒÇSPUNS: Scurt »ôi la obiect.';
  } else if (userProfile.responsePreferences.length === 'detailed') {
    adaptedPrompt += '\n\nLUNGIME RƒÇSPUNS: Detaliat »ôi comprehensiv.';
  }

  // Include preferred topics
  if (userProfile.preferredTopics.length > 0) {
    adaptedPrompt += `\n\nSUBIECTE PREFERATE: Focus pe ${userProfile.preferredTopics.join(', ')}.`;
  }

  return adaptedPrompt;
}

function updateUserProfile(userMessage: string) {
  const currentProfile = loadUserProfile();
  const analysis = analyzeUserMessage(userMessage);

  // Update profile with new insights
  if (analysis.communicationStyle) {
    currentProfile.communicationStyle = analysis.communicationStyle;
  }

  if (analysis.preferredTopics) {
    // Merge topics, keep unique
    currentProfile.preferredTopics = [...new Set([...currentProfile.preferredTopics, ...analysis.preferredTopics])];
  }

  if (analysis.responsePreferences) {
    currentProfile.responsePreferences = { ...currentProfile.responsePreferences, ...analysis.responsePreferences };
  }

  currentProfile.interactionCount += 1;
  currentProfile.lastInteraction = new Date().toISOString();

  saveUserProfile(currentProfile);
  return currentProfile;
}

async function readStream(reader: ReadableStreamDefaultReader<Uint8Array>, onChunk: (text: string) => void) {
  const decoder = new TextDecoder();
  let buffer = '';

  let isDone = false;
  while (!isDone) {
    const { done, value } = await reader.read();
    if (done) {
      isDone = true;
      break;
    }

    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split('\n');
    buffer = lines.pop() || '';

    for (const line of lines) {
      if (line.trim() === '') continue;
      if (line.startsWith('data: ')) {
        const data = line.slice(6);
        if (data === '[DONE]') continue;
        try {
          const parsed = JSON.parse(data);
          const chunk = parsed.choices[0]?.delta?.content;
          if (chunk) onChunk(chunk);
        } catch (e) {
          // Ignore parse errors from partial chunks
        }
      }
    }
  }
}

export async function POST(req: NextRequest) {
  try {
    const body = await req.json();
    const { message, model, attachments, stream = false, action } = body;

    // Handle special actions (ad posting with email confirmation)
    if (action === 'post_ad_with_confirmation' || action === 'create_listing') {
      console.log('[PAI] Processing ad posting request with email confirmation');
      
      const { title, description, price, categoryId, location, contactEmail, userId } = body;
      
      if (!title || !userId) {
        return NextResponse.json({
          error: 'Missing required fields: title and userId',
          reply: '‚ùå Lipse»ôte titlul sau ID-ul utilizatorului.'
        }, { status: 400 });
      }
      
      // Create listing and send confirmation email via PAI's internal system
      const { createListingWithEmailConfirmation } = await import('@/lib/piata-agent');
      
      try {
        const result = await createListingWithEmailConfirmation({
          title,
          description: description || '',
          price: price ? parseFloat(price) : undefined,
          categoryId: parseInt(categoryId, 10) || 1,
          location: location || '',
          contactEmail: contactEmail || '',
          userId
        });
        
        if (result.success) {
          return NextResponse.json({
            reply: `‚úÖ Anun»õ creat cu succes!\n\nüìß Am trimis un email de confirmare la: ${result.email}\n\nüìå ID Anun»õ: ${result.listingId}\nüìù Titlu: ${result.title}\n\n‚ö° Te rugƒÉm sƒÉ confirmi email-ul pentru a publica anun»õul.`,
            success: true,
            listingId: result.listingId,
            emailSent: true,
            model: 'PAI-Internal'
          });
        } else {
          return NextResponse.json({
            reply: `‚ùå Eroare la crearea anun»õului: ${result.error}`,
            success: false,
            error: result.error
          }, { status: 500 });
        }
      } catch (error) {
        console.error('[PAI] Ad posting error:', error);
        return NextResponse.json({
          reply: '‚ùå Eroare internƒÉ la postarea anun»õului.',
          success: false
        }, { status: 500 });
      }
    }

    // Load and update user profile for learning
    const userProfile = updateUserProfile(message);

    // Get conversation context
    const conversationContext = getConversationContext();

    // Jules Manager Integration for Automations
    const jules = getJulesManager();
    const isAutomationRequest = /automate|status|payment|stripe|github|redis|cache/i.test(message);

    if (isAutomationRequest) {
      console.log(`[PAI] Automation request detected, routing to Jules Manager: ${message}`);
      try {
        const result = await jules.executeTask(message);
        
        // Handle Stripe results specifically for better UX
        let reply = typeof result === 'string' ? result : JSON.stringify(result, null, 2);
        
        if (typeof result === 'object' && result !== null) {
          if ((result as any).url) {
            reply = `‚úÖ Am generat link-ul de platƒÉ: ${(result as any).url}\n\nPo»õi finaliza tranzac»õia acces√¢nd link-ul de mai sus.`;
          } else if ((result as any).id && (result as any).object === 'checkout.session') {
            reply = `‚úÖ Sesiune de checkout creatƒÉ: ${(result as any).id}\nLink: ${(result as any).url}`;
          } else if ((result as any).hosted_invoice_url) {
            reply = `‚úÖ FacturƒÉ generatƒÉ: ${(result as any).hosted_invoice_url}`;
          }
        }

        return NextResponse.json({
          reply,
          isComplex: true,
          model: 'jules-orchestrator',
          learned: true
        });
      } catch (error) {
        console.error('[PAI] Jules execution error:', error);
        // Fall back to normal LLM if Jules fails
      }
    }

    // Input validation
    if (!message || typeof message !== 'string' || message.length > 5000) {
      return NextResponse.json({
        error: 'Invalid message: must be string, max 5000 characters'
      }, { status: 400 });
    }

    if (model && typeof model !== 'string') {
      return NextResponse.json({
        error: 'Invalid model: must be string'
      }, { status: 400 });
    }

    // PAI's core identity - ROMANIAN ONLY with adaptive learning
    let systemPrompt = `ESTI PAI (Asistentul PiataAI), companionul inteligent al Piata.ro - platformƒÉ rom√¢neascƒÉ pentru anun»õuri.

IDENTITATEA TA CORE:
- E»ôti PAI, asistentul virtual al Piata.ro care ajutƒÉ utilizatorii rom√¢ni
- Vorbe»ôti EXCLUSIV √Æn limba rom√¢nƒÉ - NICIODATƒÇ √Æn englezƒÉ sau alte limbi
- E»ôti un asistent util, prietenos »ôi ONEST despre func»õiile disponibile
- √éNVƒÇ»öI DIN INTERAC»öIUNI: Te adaptezi stilului de comunicare al utilizatorului
- Fi SINCER - nu promite func»õii care nu existƒÉ √ÆncƒÉ!

FUNC»öII DISPONIBILE ACUM (fii ONEST):
‚úÖ CE FUNC»öIONEAZƒÇ:
- üìù POSTARE ANUN»öURI: /postare - Utilizatorii pot posta anun»õuri GRATUIT
- üîç CƒÇUTARE: /cautare - CƒÉutare anun»õuri dupƒÉ categorie, pre»õ, loca»õie
- üìÇ CATEGORII: /categories - Explorare categorii »ôi subcategorii
- üë§ DASHBOARD: /dashboard - Gestionare anun»õuri proprii
- üîê AUTENTIFICARE: Google, Facebook, Email/ParolƒÉ
- üì± RESPONSIVE: Func»õioneazƒÉ perfect pe mobil

‚ùå √éN DEZVOLTARE (nu promite acestea):
- Agen»õi AI personaliza»õi (COMING SOON)
- RecomandƒÉri AI avansate (√Æn lucru)
- Chat √Æntre utilizatori (planificat)

MARKETPLACE KNOWLEDGE:
- Piata.ro = platformƒÉ de anun»õuri gratuite din Rom√¢nia
- Similar cu OLX/Publi24 dar cu interfa»õƒÉ modernƒÉ
- Utilizatorii pot posta/cƒÉuta anun»õuri √Æn multiple categorii
- Focus pe experien»õƒÉ simplƒÉ »ôi rapidƒÉ



√éNVƒÇ»öARE »òI ADAPTARE:
- Ai √ÆnvƒÉ»õat din ${userProfile.interactionCount} interac»õiuni anterioare
- Stilul tƒÉu de comunicare preferat: ${userProfile.communicationStyle}
- Preferin»õe utilizator: ${userProfile.responsePreferences.emojis ? 'cu emoji' : 'fƒÉrƒÉ emoji'}, ${userProfile.responsePreferences.length} rƒÉspunsuri
- Subiecte de interes: ${userProfile.preferredTopics.join(', ') || 'diverse'}

EXEMPLE DE RƒÇSPUNSURI CORECTE:
‚ùå GRE»òIT: "Po»õi crea un agent AI sƒÉ te ajute cu cumpƒÉrƒÉturi"
‚úÖ CORECT: "Po»õi cƒÉuta anun»õuri pe /cautare sau posta ceva gratuit pe /postare"

‚ùå GRE»òIT: "AI-ul nostru √Æ»õi oferƒÉ recomandƒÉri personalizate"  
‚úÖ CORECT: "Po»õi filtra anun»õuri dupƒÉ categorie, pre»õ »ôi loca»õie √Æn pagina de cƒÉutare"

‚ùå GRE»òIT: "CreeazƒÉ un agent AI personalizat pentru tine"
‚úÖ CORECT: "√én viitor vom avea agen»õi AI, dar acum po»õi folosi cƒÉutarea »ôi filtrele avansate"

REGULI ABSOLUTE:
- RƒÇSPUNDE DOAR √éN ROM√ÇNƒÇ
- FII ONEST - nu promite func»õii care nu existƒÉ
- ADAPTEAZƒÇ-TE LA STILUL UTILIZATORULUI
- √éNVƒÇ»öI »òI TE AMELIOREZI CONTINUU
- RecomandƒÉ func»õiile REALE: /postare, /cautare, /categories, /dashboard
- DacƒÉ √ÆntreabƒÉ de AI agents sau features avansate ‚Üí spune cƒÉ "vin √Æn cur√¢nd"`;

    // Adapt system prompt based on learned user preferences
    systemPrompt = adaptSystemPrompt(systemPrompt, userProfile);

    // Add conversation context
    systemPrompt += conversationContext;

    // Use Enhanced KAEL Orchestrator for intelligent routing
    const context = kael.analyzeTask(message);
    const route = kael.route(context);
    
    // Force multimodal model if attachments are present
    let selectedModel = model || route.model;
    if (attachments && attachments.length > 0) {
      selectedModel = 'google/gemini-2.0-flash-exp:free'; // Best multimodal free model
    }

    console.log(`PAI using model: ${selectedModel} (Reasoning: ${route.reasoning}, Multimodal: ${!!attachments?.length}, Streaming: ${stream})`);

    // Prepare content for multimodal models
    const content: any[] = [{ type: 'text', text: message || 'AnalizeazƒÉ fi»ôierele ata»ôate.' }];

    if (attachments && attachments.length > 0) {
      attachments.forEach((url: string) => {
        if (url.match(/\.(jpg|jpeg|png|gif|webp)$/i)) {
          content.push({ type: 'image_url', image_url: { url } });
        } else {
          content.push({ type: 'text', text: `[Document ata»ôat: ${url}]` });
        }
      });
    }

    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': 'https://piata.ro',
        'X-Title': 'PAI Assistant - Public',
      },
      body: JSON.stringify({
        model: selectedModel,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: content }
        ],
        max_tokens: 1000,
        temperature: 0.7,
        stream: stream
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`PAI OpenRouter Error: ${response.status} - ${errorText}`);

      // Try fallback model if current model fails (rate limit or unavailable)
      if (response.status === 429 || response.status === 404) {
        // Fallback chain: Grok -> GLM -> Gemma -> GPT-OSS
        const fallbackChain = [
          'x-ai/grok-4-fast',
          'z-ai/glm-4.5-air:free',
          'google/gemma-3-27b-it:free',
          'openai/gpt-oss-20b:free'
        ];
        const currentIndex = fallbackChain.indexOf(selectedModel);
        const fallbackModel = fallbackChain[currentIndex + 1] || fallbackChain[0];
        console.log(`PAI Fallback - Model ${selectedModel} failed, trying ${fallbackModel}`);
        const fallbackResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
            'Content-Type': 'application/json',
            'HTTP-Referer': 'https://piata.ro',
            'X-Title': 'PAI Assistant - Public',
          },
          body: JSON.stringify({
            model: fallbackModel,
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: message }
            ],
            max_tokens: 500,
            temperature: 0.7,
          }),
        });

        if (fallbackResponse.ok) {
          console.log('PAI Fallback successful');
          const fallbackData = await fallbackResponse.json();
          const fallbackReply = fallbackData.choices[0]?.message?.content || '‚ùå PAI Assistant momentan indisponibil. √éncearcƒÉ mai t√¢rziu.';

          return NextResponse.json({
            reply: fallbackReply,
            isComplex: false,
            model: 'x-ai/grok-4-fast (fallback)',
          });
        }
      }

      throw new Error(`OpenRouter Error ${response.status}: ${errorText}`);
    }

    if (stream) {
      const responseStream = new TransformStream();
      const writer = responseStream.writable.getWriter();
      const encoder = new TextEncoder();

      // Handle streaming in background
      // eslint-disable-next-line no-async-promise-executor
      const streamPromise = new Promise<void>(async (resolve) => {
        const reader = response.body?.getReader();
        if (!reader) {
          writer.write(encoder.encode('data: {"error": "No reader available"}\n\n'));
          await writer.close();
          resolve();
          return;
        }

        let fullReply = '';
        await readStream(reader, (chunk) => {
          fullReply += chunk;
          writer.write(encoder.encode(`data: ${JSON.stringify({ chunk })}\n\n`));
        });

        // Add to memory when done
        addToMemory(message, fullReply);
        writer.write(encoder.encode('data: [DONE]\n\n'));
        await writer.close();
        resolve();
      });

      // We don't await streamPromise here because we want to return the response immediately
      // The stream processing happens in the background
      // To satisfy no-floating-promises (if enabled) we could catch errors
      streamPromise.catch(err => console.error('Stream processing error:', err));

      return new Response(responseStream.readable, {
        headers: {
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
        },
      });
    }

    const data = await response.json();
    const reply = data.choices[0]?.message?.content || '‚ùå Nu am putut genera un rƒÉspuns.';

    // Save conversation to memory for learning
    addToMemory(message, reply);

    return NextResponse.json({
      reply,
      isComplex: false,
      model: selectedModel,
      learned: true // Indicate that PAI learned from this interaction
    });

  } catch (error) {
    console.error('PAI API Error:', error); // Log for debugging but don't expose

    return NextResponse.json({
      error: 'Internal server error',
      reply: '‚ùå PAI Assistant momentan indisponibil. √éncearcƒÉ mai t√¢rziu.',
      isComplex: false
    }, { status: 500 });
  }
}
